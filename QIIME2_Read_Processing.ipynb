{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# QIIME 2 Tutorial: Read Processing\n",
        "\n",
        "This notebook contains materials adapted from a google colab notebook created by the QIIME2 team: https://colab.research.google.com/github/bokulich-lab/uzh-microbiome-tutorial/blob/main/01_read_processing.ipynb; all source code is licensed under the Apache License 2.0.\n",
        "\n",
        "Save your own local copy of this notebook by using `File > Save a copy in Drive`. At some point you may be prompted to trust the notebook. Trust me, it is safe ðŸ¤ž\n",
        "\n",
        "**Disclaimer:**\n",
        "\n",
        "The Google Colab notebook environment will interpret any command as Python code by default. If we want to run bash commands we will have to prefix them by `!`. So any command you see with a leading `!` is a bash command and if you wanted to run it in your terminal you would omit the leading `!`. For example, if in the Colab notebook you ran `!wget` you would just run `wget` in your terminal.\n",
        "\n",
        "In this notebook we use the `!` prefix because we run all QIIME 2 commands using the [`q2cli`](https://github.com/qiime2/q2cli/) (QIIME 2 command-line interface). However, QIIME 2 also has a python API and a Galaxy interface. You can learn more about these and other QIIME 2 interfaces at https://qiime2.org/.\n",
        "\n",
        "You can run the entire notebook by selecting `Runtime > Run all` from the menu in Google Colab. Some steps are time-comsuming and the entire notebook may take up to 30-60 minutes, so run the entire notebook now and we will inspect the commands and results as we work through as a class."
      ],
      "metadata": {
        "id": "H67cTPid42PX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: Setup\n",
        "\n",
        "Lets start with the setup. We will import materials from a github repository and go into the materials folder. We will the run a script created by the qiime2 team to install qiime2 and all the plugins. Afterwards we will import the necessary python libraries."
      ],
      "metadata": {
        "id": "m9QrYDLzBcSX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yUqWuhRL4uwQ",
        "outputId": "23763f19-549c-4567-862f-1fa5d32a73f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'materials'...\n",
            "fatal: could not read Username for 'https://github.com': No such device or address\n",
            "mkdir: cannot create directory â€˜/content/prefetch_cacheâ€™: File exists\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/zajacn/QIIME2_Read_Processing.git materials\n",
        "! mkdir /content/prefetch_cache"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd materials"
      ],
      "metadata": {
        "id": "cVY9PniMBF_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we are ready to set up our environment. This will take about 10 minutes.\n",
        "**Note:** This setup is only relevant for Google Colaboratory and will not work on your local machine. Please follow the [official installation instructions](https://docs.qiime2.org/2023.9/install/) for that. This setup is taken from the setup prepared by bokulich lab."
      ],
      "metadata": {
        "id": "2TxwhxvsyK_g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%run setup_qiime2"
      ],
      "metadata": {
        "id": "cmGD9E20BHzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "HY48M_CgBY2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Import the data.\n",
        "\n",
        "First what we need to do is convert the fastq sequenced reads into a single object in a qiime2 format (with a qza extension). In order to do that you need a manifest file (manifest.tsv) which provides qiime2 with the absolute path to all the reads. You also need to specify the type of the data and the input format.\n",
        "\n",
        "Lets check first what are the possible input formats. See the following link for more information: https://docs.qiime2.org/2024.2/tutorials/importing/\n"
      ],
      "metadata": {
        "id": "Ffr0Ek_hCeih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!qiime tools list-formats --importable"
      ],
      "metadata": {
        "id": "NJwG57tiFcy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see you can import any type of data. If you want to start running qiime2 from any type of data you have previously analysed with another tools, you can also do that. Just find the right format to import. Ok lets run the import then."
      ],
      "metadata": {
        "id": "zHUsVU57Fnyr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!qiime tools import --type SampleData[SequencesWithQuality] \\\n",
        "                    --input-path data/manifest.tsv \\\n",
        "                    --output-path data/demux_seqs.qza \\\n",
        "                    --input-format SingleEndFastqManifestPhred33V2"
      ],
      "metadata": {
        "id": "1ynNEx4vCZKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!qiime demux summarize --i-data data/demux_seqs.qza \\\n",
        "                       --o-visualization demux_seqs.qzv"
      ],
      "metadata": {
        "id": "rHm9hOe9F8wN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now have a look at the demux_seqs.qzv file. How do you do that? You have to go to the folder icon: on the left (just underneath ðŸ”‘). Find the demux_seqs.qzv file and download it onto your computer. Then go to [view.qiime2.org](https://view.qiime2.org) and upload that file there. This will produce a report.\n",
        "\n",
        "\n",
        "Question: How should you trim your reads?"
      ],
      "metadata": {
        "id": "UJAw3tDHGCCt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3. Denoise amplicon sequence variants.\n",
        "\n",
        "Now that you have imported your reads into qiime you want to construct a feature table. Feature table is a type of artifact accepted by many QIIME 2 plugins/actions and used in many downstream analyses.\n",
        "\n",
        "There are several ways to construct a feature table in QIIME 2. The major choice to make while working with sequencing data is between ASVs and OTUs. ASVs - clustering the reads by 99%-100% similarity, OTUs - clustering the reads by 97% similarity. Below you will see how to perform denoising of sequences to produce a table of ASVs.\n",
        "\n",
        "DADA2: Amplicon Sequence Variants\n",
        "There exist several tools one can use for denoising of NGS reads. Here, we will use DADA2 to create a feature table of ASVs. DADA2 builds an error model which can identify differences between sequences, filters out noisy sequences and generates a feature table with error-corrected sequences.\n",
        "\n",
        "To denoise the single-end reads we execute the cell below, specifying some additional parameters/outputs:\n",
        "\n",
        "*   p-trunc-len - we will truncate the reads to 135 bp (sequences shorter than this will be removed automatically)\n",
        "*   p-n-threads - if we have more than 1 CPU available, we can specify the number here to make the processing faster\n",
        "*   output-dir:\n",
        "  *   o-table - this will be our ASVs feature table\n",
        "  *   o-representative-sequences - this will be a list of all the denoised features (DNA sequences)\n",
        "  *   o-denoising-stats - this will be some stats from the denoising process"
      ],
      "metadata": {
        "id": "pbWJ-xCqHoNn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!qiime dada2 denoise-single --i-demultiplexed-seqs data/demux_seqs.qza  \\\n",
        "                            --p-trim-left TRIM_LEFT  \\\n",
        "                            --p-trunc-len TRUNC_LEN   \\\n",
        "                            --o-table table.qza   \\\n",
        "                            --o-representative-sequences dada2_rep_set.qza   \\\n",
        "                            --o-denoising-stats dada2_denoising_stats.qza"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "W6TjxhXtI7us",
        "outputId": "8116f77f-0a0d-4cc2-a8e4-b95453639356"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-2-4ff6f032dc9f>, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-4ff6f032dc9f>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    iime dada2 denoise-single --i-demultiplexed-seqs demux_seqs.qza  --p-trim-left TRIM_LEFT  --p-trunc-len TRUNC_LEN   --o-table table.qza   --o-representative-sequences dada2_rep_set.qza   --o-denoising-stats dada2_denoising_stats.qza\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional\n",
        "! qiime metadata tabulate \\\n",
        "    --m-input-file dada2_denoising_stats.qza \\\n",
        "    --o-visualization dada2_denoising_stats.qzv"
      ],
      "metadata": {
        "id": "NO5YO5FWJego"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! qiime feature-table summarize \\\n",
        "    --i-table table.qza \\\n",
        "    --m-sample-metadata-file data/sample_metadata.tsv \\\n",
        "    --o-visualization table.qzv"
      ],
      "metadata": {
        "id": "AuBsdBLMJiMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional\n",
        "! qiime feature-table tabulate-seqs \\\n",
        "    --i-data representative_sequences.qza \\\n",
        "    --o-visualization representative_sequences.qzv"
      ],
      "metadata": {
        "id": "z4E_V3tIJlYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After you have run all of these commands, have a look at the reports. As per usual, download .qzv files and upload them to view.qiime2.org.\n",
        "\n",
        "\n",
        "Questions:\n",
        " * What is the percentage or reads that remains after all the filtering?"
      ],
      "metadata": {
        "id": "1bEd88jqJmRh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 4. Generate a phylogenetic tree.\n",
        "\n",
        "We need to now generate a phylogenetic tree for diversity metrics. A tree is usually generate in a newick format and you can view that file using [iTOL](https://itol.embl.de/upload.cgi) or [phylo.io](https://beta.phylo.io/viewer/)."
      ],
      "metadata": {
        "id": "fCNqAfcAP-5j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! qiime phylogeny align-to-tree-mafft-fasttree \\\n",
        "    --i-sequences representative_sequences.qza \\\n",
        "    --output-dir phylogeny"
      ],
      "metadata": {
        "id": "KxFkJLecP-CK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lets estimate some diversity metrics\n",
        "\n",
        "First lets generate all diversity metrics. This is usually done by subsampling all samples to the same depth. If you have a huge variability in the depth of your samples this will cause loss of information from the samples that are have higher sequencing depht then the rest.\n",
        "\n",
        "Afterwards we measure the significance in faith PD alpha diversity across all the samples.\n",
        "\n",
        "And the finally we will create an Emperor plot (3D PCA) plot\n"
      ],
      "metadata": {
        "id": "I7YC_c3xQ96c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! qiime diversity core-metrics-phylogenetic \\\n",
        "    --i-phylogeny phylogeny/rooted_tree.qza \\\n",
        "    --i-table table.qza \\\n",
        "    --p-sampling-depth 1100 \\\n",
        "    --m-metadata-file data/sample_metadata.tsv \\\n",
        "    --output-dir core-metrics-results"
      ],
      "metadata": {
        "id": "Mx4Fe0UMn4jn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! qiime diversity alpha-group-significance \\\n",
        "    --i-alpha-diversity core-metrics-results/faith_pd_vector.qza \\\n",
        "    --m-metadata-file data/sample_metadata.tsv \\\n",
        "    --o-visualization core-metrics-results/faith_pd_group_significance.qzv"
      ],
      "metadata": {
        "id": "sh14HDELn5IK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! qiime emperor plot \\\n",
        "    --i-pcoa core-metrics-results/bray_curtis_pcoa_results.qza \\\n",
        "    --m-metadata-file data/sample_metadata.tsv \\\n",
        "    --o-visualization core-metrics-results/bray_curtis_pcoa.qzv"
      ],
      "metadata": {
        "id": "yZ5jveLatyEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the PCoAa and have a look at the clustering of samples. Do you identify anything unusual?"
      ],
      "metadata": {
        "id": "VMxP9pk4v22c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 5: Classify sequences by taxonomy\n",
        "\n",
        "There are several ways to classify your sequences into bacterial species. One of them is to use consensus assignment based on e.g. BLAST search of a sequence against a database of known sequences. Another one is using a machine learning classifier trained on a reference database to recognize corresponding bacterial species. We will use a pretrained classifier to identify bacterial species present in our samples.\n",
        "\n",
        "We can use the `classify-sklearn` action from the feature-classifier plugin to do that. This step will require the `FeatureData[Sequence]` artifact (containing our ASVs) that we generated previously and a pre-trained taxonomic classifier. The classifier is based on SILVA database. There are many different databases you can use. The most often used ones are [SILVA](https://www.arb-silva.de/) and [Greengenes](https://greengenes.secondgenome.com/)"
      ],
      "metadata": {
        "id": "lLPqnXmPt3IG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! wget https://data.qiime2.org/2023.9/common/gg-13-8-99-515-806-nb-weighted-classifier.qza"
      ],
      "metadata": {
        "id": "WxHl5cqFukEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! qiime feature-classifier classify-sklearn \\\n",
        "    --i-reads representative_sequences.qza \\\n",
        "    --i-classifier gg-13-8-99-515-806-nb-weighted-classifier.qza \\\n",
        "    --p-n-jobs 2 \\\n",
        "    --output-dir taxonomy"
      ],
      "metadata": {
        "id": "5pjFZVJ_unVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! qiime metadata tabulate \\\n",
        "    --m-input-file taxonomy/classification.qza \\\n",
        "    --o-visualization taxonomy/classification.qzv"
      ],
      "metadata": {
        "id": "GqcX70G0uorF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! qiime taxa barplot \\\n",
        "    --i-table table.qza \\\n",
        "    --i-taxonomy taxonomy/classification.qza \\\n",
        "    --m-metadata-file data/sample_metadata.tsv \\\n",
        "    --o-visualization taxonomy/taxa_barplot.qzv"
      ],
      "metadata": {
        "id": "vqO1yKgmurdj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the taxa_barplot visualisation. Which genus do you identify as differentially abundant between gut and the two hands?"
      ],
      "metadata": {
        "id": "wsf6sKVkviPS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optional section: Understand differentially abundant features\n",
        "\n",
        "This section may be omitted for time, but provides an interesting mechanistic view of microbiome interactions.\n",
        "\n",
        "Differential abundance in QIIME2 can be measured with various different metrics. One of them is ANCOMBC2: https://www.nature.com/articles/s41592-023-02092-7"
      ],
      "metadata": {
        "id": "fzDVbqN6u1u7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir diff_abund\n",
        "\n",
        "! qiime taxa collapse \\\n",
        "    --i-table table.qza \\\n",
        "    --i-taxonomy taxonomy/classification.qza \\\n",
        "    --p-level 6 \\\n",
        "    --o-collapsed-table diff_abund/table_l6.qza"
      ],
      "metadata": {
        "id": "HO9zrVJtutfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! qiime composition add-pseudocount \\\n",
        "    --i-table diff_abund/table_l6.qza \\\n",
        "    --o-composition-table diff_abund/comp_table_l6.qza"
      ],
      "metadata": {
        "id": "Ji_tYZZrvNg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! qiime feature-table filter-samples \\\n",
        "    --i-table diff_abund/comp_table_l6.qza \\\n",
        "    --m-metadata-file data/sample_metadata.tsv \\\n",
        "    --p-where \"[body-site]='gut'\" \\\n",
        "    --o-filtered-table diff_abund/comp_gut_table_l6.qza"
      ],
      "metadata": {
        "id": "xcpke9I1vPA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! qiime composition ancom \\\n",
        "    --i-table diff_abund/comp_gut_table_l6.qza \\\n",
        "    --m-metadata-file data/sample_metadata.tsv \\\n",
        "    --m-metadata-column subject \\\n",
        "    --o-visualization diff_abund/ancom_gut_subject_l6.qzv"
      ],
      "metadata": {
        "id": "5sdZZwfivQYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the visualisation (ancom_gut_subject_l6.qzv). How many features are differentially abundant?"
      ],
      "metadata": {
        "id": "KQbJx2ZJvYq-"
      }
    }
  ]
}